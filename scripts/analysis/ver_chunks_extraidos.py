#!/usr/bin/env python3
"""
Mostrar los chunks de texto extraÃ­do tal como se envÃ­an a OpenAI
"""

import os
from core.ai_pipeline.parsers.robust_pdf_parser import RobustPDFParser
from core.llm_pdf_parser import LLMPDFParser

def mostrar_chunks_completos():
    """Muestra todos los chunks extraÃ­dos del PDF"""

    print("ğŸ” CHUNKS DE TEXTO EXTRAÃDO")
    print("=" * 60)

    pdf_path = "/Users/danielgoes96/Desktop/mcp-server/uploads/statements/9_20250928_000304_Periodo_JUL 2025 (1).pdf"

    if not os.path.exists(pdf_path):
        print(f"âŒ PDF no encontrado: {pdf_path}")
        return

    # 1. Extraer texto completo
    print("ğŸ“„ PASO 1: Extrayendo texto completo del PDF...")
    robust_parser = RobustPDFParser()
    texto_completo = robust_parser.extract_text(pdf_path)

    print(f"âœ… Texto extraÃ­do: {len(texto_completo):,} caracteres")
    print(f"ğŸ“ LÃ­neas totales: {texto_completo.count('\\n'):,}")

    # 2. Dividir en chunks
    print("\\nğŸ“¦ PASO 2: Dividiendo en chunks...")
    llm_parser = LLMPDFParser()
    chunks = llm_parser._split_text_for_llm(texto_completo)

    print(f"âœ… Total chunks creados: {len(chunks)}")

    # 3. Mostrar cada chunk
    for i, chunk in enumerate(chunks):
        print(f"\\n{'='*80}")
        print(f"ğŸ“¦ CHUNK {i+1} de {len(chunks)}")
        print(f"{'='*80}")
        print(f"ğŸ“ TamaÃ±o: {len(chunk):,} caracteres")
        print(f"ğŸ“„ LÃ­neas: {chunk.count('\\n'):,}")

        # Contar indicadores de transacciones
        jul_count = chunk.upper().count('JUL.')
        deposito_count = chunk.upper().count('DEPOSITO')
        spei_count = chunk.upper().count('SPEI')
        cargo_count = chunk.upper().count('CARGO')
        abono_count = chunk.upper().count('ABONO')

        print(f"ğŸ“Š Indicadores encontrados:")
        print(f"   â€¢ JUL.: {jul_count}")
        print(f"   â€¢ DEPOSITO: {deposito_count}")
        print(f"   â€¢ SPEI: {spei_count}")
        print(f"   â€¢ CARGO: {cargo_count}")
        print(f"   â€¢ ABONO: {abono_count}")

        # Mostrar las primeras 30 lÃ­neas del chunk
        lineas = chunk.split('\\n')
        print(f"\\nğŸ“‹ PRIMERAS 30 LÃNEAS DEL CHUNK:")
        print("-" * 60)
        for j, linea in enumerate(lineas[:30]):
            if linea.strip():
                print(f"{j+1:3d}: {linea.strip()}")

        if len(lineas) > 30:
            print(f"     ... y {len(lineas) - 30} lÃ­neas mÃ¡s")

        # Buscar lÃ­neas que empiecen con fechas
        lineas_fecha = []
        for linea in lineas:
            linea_clean = linea.strip()
            if linea_clean.startswith('JUL.') or 'JUL' in linea_clean[:10]:
                lineas_fecha.append(linea_clean)

        if lineas_fecha:
            print(f"\\nğŸ“… LÃNEAS CON FECHAS DETECTADAS ({len(lineas_fecha)}):")
            print("-" * 40)
            for k, linea_fecha in enumerate(lineas_fecha[:10]):  # Solo primeras 10
                print(f"{k+1:2d}: {linea_fecha}")
            if len(lineas_fecha) > 10:
                print(f"     ... y {len(lineas_fecha) - 10} lÃ­neas mÃ¡s con fechas")

        # Mostrar las Ãºltimas 10 lÃ­neas del chunk
        print(f"\\nğŸ“‹ ÃšLTIMAS 10 LÃNEAS DEL CHUNK:")
        print("-" * 40)
        for j, linea in enumerate(lineas[-10:], len(lineas)-9):
            if linea.strip():
                print(f"{j:3d}: {linea.strip()}")

        # Pausa para revisiÃ³n
        if i < len(chunks) - 1:
            print(f"\\nâ¸ï¸  Presiona ENTER para ver el siguiente chunk...")
            input()

def analizar_distribucion_transacciones():
    """Analiza cÃ³mo se distribuyen las transacciones entre chunks"""

    print(f"\\nğŸ” ANÃLISIS DE DISTRIBUCIÃ“N")
    print("=" * 50)

    pdf_path = "/Users/danielgoes96/Desktop/mcp-server/uploads/statements/9_20250928_000304_Periodo_JUL 2025 (1).pdf"

    robust_parser = RobustPDFParser()
    texto_completo = robust_parser.extract_text(pdf_path)

    llm_parser = LLMPDFParser()
    chunks = llm_parser._split_text_for_llm(texto_completo)

    total_jul = 0
    for i, chunk in enumerate(chunks):
        jul_count = chunk.upper().count('JUL.')
        total_jul += jul_count
        print(f"Chunk {i+1}: {jul_count:2d} fechas JUL.")

    # Contar total en texto completo
    total_jul_completo = texto_completo.upper().count('JUL.')

    print(f"\\nğŸ“Š RESUMEN:")
    print(f"   Fechas JUL. en texto completo: {total_jul_completo}")
    print(f"   Fechas JUL. suma de chunks: {total_jul}")
    print(f"   Diferencia: {total_jul_completo - total_jul}")

    if total_jul_completo == total_jul:
        print("   âœ… Todas las fechas estÃ¡n en los chunks")
    else:
        print("   âš ï¸ Algunas fechas se perdieron al dividir en chunks")

if __name__ == "__main__":
    mostrar_chunks_completos()
    analizar_distribucion_transacciones()